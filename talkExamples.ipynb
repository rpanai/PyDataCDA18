{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultiProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fldrs = [\"data/csv/atmc10\", \"data/parq/atmc10\",\n",
    "         \"data/csv/atmc50\", \"data/parq/atmc50\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallelize(fun, vec, pool):\n",
    "    with mp.Pool(pool) as p:\n",
    "        res = p.map(fun, vec)\n",
    "    return(res)\n",
    "\n",
    "\n",
    "def funCSV(x):\n",
    "    df = pd.read_csv(x)\n",
    "    return [df[\"key\"].unique()[0], df[\"values\"].mean()]\n",
    "\n",
    "\n",
    "def funPARQ(x):\n",
    "    df = pd.read_parquet(x)\n",
    "    return [df[\"key\"].unique()[0], df[\"values\"].mean()]\n",
    "\n",
    "ncpu = os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.24 s ± 56.8 ms per loop (mean ± std. dev. of 7 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n5\n",
    "fldr = fldrs[0]\n",
    "files = [os.path.join(fldr, x) for x in os.listdir(fldr)]\n",
    "out = parallelize(funCSV, files, ncpu//2)\n",
    "out = pd.DataFrame(out, columns=[\"key\",\"values\"])\n",
    "out[\"key\"] =  out[\"key\"].astype(str)\n",
    "out = out.sort_values(\"key\").set_index(\"key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.53 s ± 114 ms per loop (mean ± std. dev. of 7 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n5\n",
    "fldr = fldrs[0]\n",
    "files = [os.path.join(fldr, x) for x in os.listdir(fldr)]\n",
    "out = parallelize(funCSV, files, ncpu)\n",
    "out = pd.DataFrame(out, columns=[\"key\",\"values\"])\n",
    "out[\"key\"] =  out[\"key\"].astype(str)\n",
    "out = out.sort_values(\"key\").set_index(\"key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.8 s ± 576 ms per loop (mean ± std. dev. of 7 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n5\n",
    "fldr = fldrs[2]\n",
    "files = [os.path.join(fldr, x) for x in os.listdir(fldr)]\n",
    "out = parallelize(funCSV, files, ncpu//2)\n",
    "out = pd.DataFrame(out, columns=[\"key\",\"values\"])\n",
    "out[\"key\"] = out[\"key\"].astype(str)\n",
    "out = out.sort_values(\"key\").set_index(\"key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.6 s ± 94.4 ms per loop (mean ± std. dev. of 7 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n5\n",
    "fldr = fldrs[2]\n",
    "files = [os.path.join(fldr, x) for x in os.listdir(fldr)]\n",
    "out = parallelize(funCSV, files, ncpu)\n",
    "out = pd.DataFrame(out, columns=[\"key\",\"values\"])\n",
    "out[\"key\"] = out[\"key\"].astype(str)\n",
    "out = out.sort_values(\"key\").set_index(\"key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.82 s ± 83.4 ms per loop (mean ± std. dev. of 7 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n5\n",
    "fldr = fldrs[1]\n",
    "files = [os.path.join(fldr, x) for x in os.listdir(fldr)]\n",
    "out = parallelize(funPARQ, files, ncpu//2)\n",
    "out = pd.DataFrame(out, columns=[\"key\",\"values\"])\n",
    "out[\"key\"] =  out[\"key\"].astype(str)\n",
    "out = out.sort_values(\"key\").set_index(\"key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.33 s ± 89.8 ms per loop (mean ± std. dev. of 7 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n5\n",
    "fldr = fldrs[1]\n",
    "files = [os.path.join(fldr, x) for x in os.listdir(fldr)]\n",
    "out = parallelize(funPARQ, files, ncpu)\n",
    "out = pd.DataFrame(out, columns=[\"key\",\"values\"])\n",
    "out[\"key\"] =  out[\"key\"].astype(str)\n",
    "out = out.sort_values(\"key\").set_index(\"key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.5 s ± 303 ms per loop (mean ± std. dev. of 7 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n5\n",
    "fldr = fldrs[3]\n",
    "files = [os.path.join(fldr, x) for x in os.listdir(fldr)]\n",
    "out = parallelize(funPARQ, files, ncpu//2)\n",
    "out = pd.DataFrame(out, columns=[\"key\",\"values\"])\n",
    "out[\"key\"] =  out[\"key\"].astype(str)\n",
    "out = out.sort_values(\"key\").set_index(\"key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.7 s ± 276 ms per loop (mean ± std. dev. of 7 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n5\n",
    "fldr = fldrs[3]\n",
    "files = [os.path.join(fldr, x) for x in os.listdir(fldr)]\n",
    "out = parallelize(funPARQ, files, ncpu)\n",
    "out = pd.DataFrame(out, columns=[\"key\",\"values\"])\n",
    "out[\"key\"] =  out[\"key\"].astype(str)\n",
    "out = out.sort_values(\"key\").set_index(\"key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiprocessing + Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import gc\n",
    "\n",
    "def parallelize(fun, vec, pool):\n",
    "    with mp.Pool(pool) as p:\n",
    "        res = p.map(fun, vec)\n",
    "    return(res)\n",
    "\n",
    "\n",
    "def funCSV(x):\n",
    "    df = pd.read_csv(x)\n",
    "    return [df[\"key\"].unique()[0], df[\"values\"].mean()]\n",
    "\n",
    "\n",
    "def funPARQ(x):\n",
    "    df = pd.read_parquet(x)\n",
    "    return [df[\"key\"].unique()[0], df[\"values\"].mean()]\n",
    "\n",
    "ncpu = os.cpu_count()\n",
    "\n",
    "fldrs = [\"data/csv/split10\", \"data/parq/split10\",\n",
    "         \"data/csv/split50\", \"data/parq/split50\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "823 ms ± 28.7 ms per loop (mean ± std. dev. of 7 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n5\n",
    "fldr = fldrs[0]\n",
    "files = [os.path.join(fldr, x) for x in os.listdir(fldr)]\n",
    "out = parallelize(funCSV, files, ncpu//2)\n",
    "out = pd.DataFrame(out, columns=[\"key\",\"values\"])\n",
    "out[\"key\"] =  out[\"key\"].astype(str)\n",
    "out = out.sort_values(\"key\").set_index(\"key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "846 ms ± 32.8 ms per loop (mean ± std. dev. of 7 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n5\n",
    "fldr = fldrs[1]\n",
    "files = [os.path.join(fldr, x) for x in os.listdir(fldr)]\n",
    "out = parallelize(funPARQ, files, ncpu//2)\n",
    "out = pd.DataFrame(out, columns=[\"key\",\"values\"])\n",
    "out[\"key\"] =  out[\"key\"].astype(str)\n",
    "out = out.sort_values(\"key\").set_index(\"key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 50M\n",
    "### csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.39 s ± 38 ms per loop (mean ± std. dev. of 7 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n5\n",
    "fldr = fldrs[2]\n",
    "files = [os.path.join(fldr, x) for x in os.listdir(fldr)]\n",
    "out = parallelize(funCSV, files, ncpu//2)\n",
    "out = pd.DataFrame(out, columns=[\"key\",\"values\"])\n",
    "out[\"key\"] =  out[\"key\"].astype(str)\n",
    "out = out.sort_values(\"key\").set_index(\"key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18 s ± 21 ms per loop (mean ± std. dev. of 7 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n5\n",
    "fldr = fldrs[3]\n",
    "files = [os.path.join(fldr, x) for x in os.listdir(fldr)]\n",
    "out = parallelize(funPARQ, files, ncpu//2)\n",
    "out = pd.DataFrame(out, columns=[\"key\",\"values\"])\n",
    "out[\"key\"] =  out[\"key\"].astype(str)\n",
    "out = out.sort_values(\"key\").set_index(\"key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.03 s, sys: 631 ms, total: 4.66 s\n",
      "Wall time: 3.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv(\"data/file10SRTD.csv\")\n",
    "out = df.groupby(\"key\")[\"values\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.94 s, sys: 625 ms, total: 5.56 s\n",
      "Wall time: 3.94 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv(\"data/file10SHFFL.csv\")\n",
    "out = df.groupby(\"key\")[\"values\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.18 s, sys: 949 ms, total: 4.13 s\n",
      "Wall time: 2.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_parquet(\"data/file10SRTD.parq\")\n",
    "out = df.groupby(\"key\")[\"values\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.45 s, sys: 1.08 s, total: 4.53 s\n",
      "Wall time: 2.99 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_parquet(\"data/file10SHFFL.parq\")\n",
    "out = df.groupby(\"key\")[\"values\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 50M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.5 s, sys: 2.6 s, total: 17.1 s\n",
      "Wall time: 15.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv(\"data/file50SRTD.csv\")\n",
    "out = df.groupby(\"key\")[\"values\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.2 s, sys: 2.7 s, total: 35.9 s\n",
      "Wall time: 34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv(\"data/file50SHFFL.csv\")\n",
    "out = df.groupby(\"key\")[\"values\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.88 s, sys: 5.7 s, total: 15.6 s\n",
      "Wall time: 13.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_parquet(\"data/file50SRTD.parq\")\n",
    "out = df.groupby(\"key\")[\"values\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.3 s, sys: 5.37 s, total: 20.7 s\n",
      "Wall time: 18.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_parquet(\"data/file50SHFFL.parq\")\n",
    "out = df.groupby(\"key\")[\"values\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client, LocalCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:37609\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>16</li>\n",
       "  <li><b>Cores: </b>16</li>\n",
       "  <li><b>Memory: </b>63.32 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:37609' processes=16 cores=16>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster = LocalCluster()\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fldrs = [\"data/csv/atmc10\", \"data/parq/atmc10\",\n",
    "         \"data/csv/atmc50\", \"data/parq/atmc50\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43.1 s, sys: 1.6 s, total: 44.7 s\n",
      "Wall time: 44.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = dd.read_csv(fldrs[0]+\"/*.csv\")\n",
    "out = df.groupby(\"key\")[\"values\"].mean()\\\n",
    "        .compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:41195\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>16</li>\n",
       "  <li><b>Cores: </b>16</li>\n",
       "  <li><b>Memory: </b>63.32 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:41195' processes=0 cores=0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.3 s, sys: 1.57 s, total: 28.8 s\n",
      "Wall time: 28.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = dd.read_parquet(fldrs[1]+\"/*.parq\")\n",
    "out = df.groupby(\"key\")[\"values\"].mean()\\\n",
    "        .compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 50M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:41195\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>16</li>\n",
       "  <li><b>Cores: </b>16</li>\n",
       "  <li><b>Memory: </b>63.32 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:41195' processes=16 cores=16>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 36s, sys: 7.64 s, total: 3min 44s\n",
      "Wall time: 3min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = dd.read_csv(fldrs[2]+\"/*.csv\")\n",
    "out = df.groupby(\"key\")[\"values\"].mean()\\\n",
    "        .compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:41195\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>16</li>\n",
       "  <li><b>Cores: </b>16</li>\n",
       "  <li><b>Memory: </b>63.32 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:41195' processes=0 cores=0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 15s, sys: 7.49 s, total: 2min 23s\n",
      "Wall time: 2min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = dd.read_parquet(fldrs[3]+\"/*.parq\")\n",
    "out = df.groupby(\"key\")[\"values\"].mean()\\\n",
    "        .compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask Map Partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:37229\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>16</li>\n",
       "  <li><b>Cores: </b>16</li>\n",
       "  <li><b>Memory: </b>63.32 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:37229' processes=16 cores=16>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "fldrs = [\"data/csv/atmc10\", \"data/parq/atmc10\",\n",
    "         \"data/csv/atmc50\", \"data/parq/atmc50\"]\n",
    "\n",
    "cluster = LocalCluster()\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 49.3 s, sys: 2.79 s, total: 52.1 s\n",
      "Wall time: 50.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = dd.read_csv(fldrs[0]+\"/*.csv\")\n",
    "out = df.map_partitions(lambda x:[x[\"key\"].unique()[0], x[\"values\"].mean()]).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.5 s, sys: 2.29 s, total: 33.8 s\n",
      "Wall time: 32.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = dd.read_parquet(fldrs[1]+\"/*.parq\")\n",
    "out = df.map_partitions(lambda x:[x[\"key\"].unique()[0], x[\"values\"].mean()]).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 50M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 13s, sys: 13.9 s, total: 4min 27s\n",
      "Wall time: 4min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = dd.read_csv(fldrs[2]+\"/*.csv\")\n",
    "out = df.map_partitions(lambda x:[x[\"key\"].unique()[0], x[\"values\"].mean()]).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 45s, sys: 11.7 s, total: 2min 57s\n",
      "Wall time: 2min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = dd.read_parquet(fldrs[3]+\"/*.parq\")\n",
    "out = df.map_partitions(lambda x:[x[\"key\"].unique()[0], x[\"values\"].mean()]).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 50M chuncks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:37537\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>16</li>\n",
       "  <li><b>Cores: </b>16</li>\n",
       "  <li><b>Memory: </b>63.32 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:37537' processes=16 cores=16>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "fldrs = [\"data/csv/split10\", \"data/parq/split10\",\n",
    "         \"data/csv/split50\", \"data/parq/split50\"]\n",
    "\n",
    "cluster = LocalCluster()\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 328 ms, sys: 67.3 ms, total: 396 ms\n",
      "Wall time: 1.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = dd.read_csv(fldrs[0]+\"/*.csv\")\n",
    "out = df.groupby(\"key\")[\"values\"].mean()\\\n",
    "        .compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 379 ms, sys: 63.1 ms, total: 442 ms\n",
      "Wall time: 1.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = dd.read_parquet(fldrs[1]+\"/*.parq\")\n",
    "out = df.groupby(\"key\")[\"values\"].mean()\\\n",
    "        .compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 50M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 801 ms, sys: 97.4 ms, total: 899 ms\n",
      "Wall time: 3.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = dd.read_csv(fldrs[2]+\"/*.csv\")\n",
    "out = df.groupby(\"key\")[\"values\"].mean()\\\n",
    "        .compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 715 ms, sys: 138 ms, total: 853 ms\n",
      "Wall time: 3.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = dd.read_parquet(fldrs[3]+\"/*.parq\")\n",
    "out = df.groupby(\"key\")[\"values\"].mean()\\\n",
    "        .compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 737 ms, sys: 101 ms, total: 838 ms\n",
      "Wall time: 3.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = dd.read_parquet(fldrs[3]+\"/*.parq\")\n",
    "out = df.groupby(\"key\")[\"values\"].mean()\\\n",
    "        .compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "talkCDA",
   "language": "python",
   "name": "talk_cda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
